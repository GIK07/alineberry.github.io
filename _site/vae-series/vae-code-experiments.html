<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.16.3 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>Variational Autoencoder Code and Experiments - Adam Lineberry</title>
<meta name="description" content="Final connections between theory and lines of code">



<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Adam Lineberry">
<meta property="og:title" content="Variational Autoencoder Code and Experiments">
<meta property="og:url" content="http://localhost:4000/vae-series/vae-code-experiments">


  <meta property="og:description" content="Final connections between theory and lines of code">







  <meta property="article:published_time" content="2019-07-07T00:00:00-06:00">





  

  


<link rel="canonical" href="http://localhost:4000/vae-series/vae-code-experiments">







  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Person",
      "name": "Adam Lineberry",
      "url": "http://localhost:4000",
      "sameAs": null
    }
  </script>







<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Adam Lineberry Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">

<!--[if IE ]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

  </head>

  <body class="layout--single">

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">Adam Lineberry</a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/" >About</a>
            </li><li class="masthead__menu-item">
              <a href="/machine-learning/" >Machine Learning Blog</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
            <path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
          </svg>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      

      
        <img src="/images/headshot2.jpeg" alt="Adam Lineberry" itemprop="image">
      
    </div>
  

  <div class="author__content">
    
      <h3 class="author__name" itemprop="name">Adam Lineberry</h3>
    
    
      <p class="author__bio" itemprop="description">
        Data Scientist
      </p>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name">Denver, CO</span>
        </li>
      

      
        
          
            <li><a href="https://www.linkedin.com/in/adam-lineberry/" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li>
          
        
          
            <li><a href="https://github.com/acetherace" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
          
        
          
        
          
        
          
            <li><a href="https://twitter.com/adam_lineberry_" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
          
        
          
        
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="Variational Autoencoder Code and Experiments">
    <meta itemprop="description" content="Final connections between theory and lines of code">
    <meta itemprop="datePublished" content="July 07, 2019">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">Variational Autoencoder Code and Experiments
</h1>
          
            <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  17 minute read
</p>
          
        </header>
      

      <section class="page__content" itemprop="text">
        
        <p class="notice--info">This is the fourth and final post in my series: <a href="http://localhost:4000/vae-series/">From KL Divergence to Variational Autoencoder in PyTorch</a>. The previous post in the series is <a href="http://localhost:4000/vae-series/vae-theory">Variational Autoencoder Theory</a>.</p>

<hr />

<p>In this post we will build and train a variational autoencoder (VAE) in PyTorch, tying everything back to the theory derived in my <a href="http://localhost:4000/vae-series/vae-theory">post on VAE theory</a>. The first half of the post provides discussion on the key points in the implementation. The second half provides the code itself along with some annotations.</p>

<p>The VAE in this post is trained on the MNIST dataset on a laptop CPU. The images (originally 28x28) are flattened into a 784 dimensional vector for simplicity. The MNIST pixel intensity values, originally continuous <script type="math/tex">\in [0,1]</script> are binarized such that each pixel value is <script type="math/tex">\in \{0,1\}</script>.</p>

<p>Before diving into the code, let’s set the stage by recapping the theory that has led us to this point.</p>

<p>In variational inference for latent variable models, learning a model to maximize the marginal likelihood directly is intractable so we turn to maximizing a lower bound of it instead (referred to as the evidence lower bound, or “ELBO”). We won’t go into any further details on variational inference since it is covered in depth in my <a href="http://localhost:4000/vae-series/variational-inference">post on variational inference</a>. The ELBO is then arranged in a particular way to form the objective function for the VAE:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\mathcal{L} &= \mathbb{E_{q_{\phi}(z \lvert x)}} \log p_{\theta}(x \lvert z) -
KL[q_{\phi}(z \lvert x) \lVert p_{\theta}(z)] \\
&= \sum_i \big[ \mathbb{E_{q_{\phi}(z_i \lvert x_i)}} \log p_{\theta}(x_i \lvert z_i) -
KL[q_{\phi}(z_i \lvert x_i) \lVert p_{\theta}(z_i)] \big]
\end{align} %]]></script>

<p>The basic intuition behind this objective is that the first term acts as a reconstruction loss and the KL term acts as a regularizer. This intuition is discussed in much more detail in the previous post.</p>

<p>The VAE sets a unit factorized Gaussian prior on the latent variable: <script type="math/tex">p_{\theta}(z) = \mathcal{N}(0, I)</script>, and learns the distributions <script type="math/tex">q_{\phi}(z \lvert x)</script> and <script type="math/tex">p_{\theta}(x \lvert z)</script> jointly in a single neural network. The first half of the network that maps data into a distribution over latent space is known as the <em>probabilistic encoder</em>. The second half of the network that maps samples from the latent space back into the original space is known as the <em>probabilistic decoder</em>.</p>

<p><img src="http://localhost:4000/images/vae/vae-architecture.png" alt="" class="align-center" /></p>
<figcaption>Illustration of the VAE model architecture<sup>3</sup></figcaption>

<h2 id="from-the-elbo-objective-to-a-pytorch-loss-function">From the ELBO objective to a PyTorch loss function</h2>

<p>In this section we will walk carefully from the theoretical ELBO objective function to specific PyTorch commands. We will focus on the objective one term at a time.</p>

<h3 id="first-term-reconstruction">First term (reconstruction)</h3>

<p>The first term of the ELBO objective is the expected reconstruction probability:</p>

<script type="math/tex; mode=display">\mathbb{E_{q_{\phi}(z \lvert x)}} \log p_{\theta}(x \lvert z)</script>

<p>Since the data is binary in this experiment, we will construct <script type="math/tex">p_{\theta}(x \lvert z)</script> to model a multivariate factorized Bernoulli distribution. (Note, the distribution chosen to model the reconstruction is dataset-specific. If you have continuous data then a factorized Gaussian may be more appropriate.) This means that, for each data point, we view the 784 binary pixels values as independent Bernoulli observations. As such, the decoder network will output 784 Bernoulli parameters. The Bernoulli parameter is the probability of success in a binary outcome trial <script type="math/tex">p \in [0, 1]</script> (e.g., the probability of heads when flipping a biased coin).</p>

<p>Let’s take the <script type="math/tex">j^{th}</script> pixel of the <script type="math/tex">i^{th}</script> image as an example and call it <script type="math/tex">x_{ij}</script>. Since we’re dealing with binary pixel values, <script type="math/tex">x_{ij} \in \{0,1\}</script> can be interpreted as the result of a Bernoulli trial. The model’s output will be the Bernoulli parameter corresponding to that pixel; let’s call that specific output <script type="math/tex">p_{ij} \in [0,1]</script>. The likelihood of that pixel <script type="math/tex">p_{\theta}(x_{ij} \lvert z_i)</script> is then given by the Bernoulli PMF:</p>

<script type="math/tex; mode=display">p_{ij}^{x_{ij}}(1-p_{ij})^{1-x_{ij}}</script>

<p>Since the first term in the objective deals with the log probability, we can write the log likelihood instead:</p>

<script type="math/tex; mode=display">x_{ij} \log p_{ij} + (1-x_{ij}) \log (1-p_{ij})</script>

<p>This equation may look familiar. The negative of it is commonly known as binary cross entropy and is implemented in PyTorch by <a href="https://pytorch.org/docs/stable/nn.html?highlight=binary_cross_entropy#torch.nn.BCELoss"><code class="highlighter-rouge">torch.nn.BCELoss</code></a>.</p>

<p>Now, the log likelihood of the full data point <script type="math/tex">x_i</script> is given by</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{align}
\log p_{\theta}(x_i \lvert z_i) &= \log \prod_{j=1}^{784} p_{\theta}(x_{ij} \lvert z_i) \\
&= \sum_{j=1}^{784} \log p_{\theta}(x_{ij} \lvert z_i) \\
&= \sum_{j=1}^{784} \bigg[ x_{ij} \log p_{ij} + (1-x_{ij}) \log (1-p_{ij}) \bigg]
\end{align} %]]></script>

<p>In PyTorch the final expression is implemented by <a href="https://pytorch.org/docs/stable/nn.html#binary-cross-entropy"><code class="highlighter-rouge">torch.nn.functional.binary_cross_entropy</code></a> with <code class="highlighter-rouge">reduction='sum'</code>. Since we are training in minibatches, we want the sum of log probabilities for all pixels in that minibatch. This is accomplished by simply passing full batches through the same function call. You can think of the operation performed as first summing the 784 values for each datapoint and then summing over data points in the batch. In reality, a <code class="highlighter-rouge">(batch_size, 784)</code> size tensor of cross entropy values will be computed and then summed over all axes.</p>

<p>The expectation of the log likelihood over <script type="math/tex">q_{\phi}(z \lvert x)</script> is satisfied by simply sampling one point from <script type="math/tex">q_{\phi}(z \lvert x)</script> and passing it through the decoder. Note that there are no additional complexities here; this is a basic forward pass. As discussed in the previous post, this is the Monte Carlo approximation of the expected value of a function.</p>

<h3 id="second-term-kl-divergence-regularization">Second term (KL divergence, regularization)</h3>

<p>The second term of the ELBO objective is the negative KL divergence between the variational posterior and the prior on the latent variable <script type="math/tex">z</script>:</p>

<script type="math/tex; mode=display">-KL[q_{\phi}(z \lvert x) \lVert p_{\theta}(z)]</script>

<p>Since we have defined the prior to be a factorized unit Gaussian and we have defined the variational posterior to also be a factorized Gaussian, this KL term has a clean closed-form solution. The solution is essentially just a function of the means and covariances of the two distributions. The negative KL term simplifies to</p>

<script type="math/tex; mode=display">-\frac{1}{2} \sum_{j=1}^{J} (1 + \log \sigma_j^2 - \mu_j^2 - \sigma_j^2)</script>

<p>Where <script type="math/tex">J</script> is the size of the latent space (number of dimensions), and <script type="math/tex">\mu</script> and <script type="math/tex">\sigma^2</script> are the mean and variance vectors output from the probabilistic encoder.</p>

<p>In order to compute this, the forward pass of the network must also return mean and variance vectors output from the encoder, not just the reconstruction portion. In other words, the full model must return the outputs from both the encoder and the decoder.</p>

<p>The KL term can be computed across a minibatch with the following:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">logvar</span> <span class="o">-</span> <span class="n">mu</span><span class="o">.</span><span class="nb">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">logvar</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span>
</code></pre></div></div>

<p>Where <code class="highlighter-rouge">mu</code> and <code class="highlighter-rouge">logvar</code> are tensors of means and log variances across the minibatch, respectively. Both of these tensors will have size <code class="highlighter-rouge">(batch_size, latent_space_size)</code>.</p>

<h3 id="putting-the-terms-together">Putting the terms together</h3>

<p>In the following implementation, the binary cross entropy (BCE) and the KL divergence are calculated across the minibatch separately and simply summed at the end.</p>

<h2 id="sampling-from-the-encoder">Sampling from the encoder</h2>

<p>A key step in the flow of the VAE is sampling a data point from the encoder <script type="math/tex">q_{\phi}(z_i \lvert x_i)</script>. The reparameterization trick is used to perform this sampling without introducing a discontinuity in the network (as discussed in the previous post).</p>

<script type="math/tex; mode=display">z_i = g_{\phi}(x_i, \epsilon_i) = \mu_{\phi}(x_i) + diag(\sigma_{\phi}(x_i)) \cdot \epsilon_i \\
\epsilon_i \sim \mathcal{N}(0, I)</script>

<p>In the forward pass, the vector of means and log variances are collected from the encoder. These vectors are used to generate a data sample as such</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">reparameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">):</span>
  <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span><span class="o">*</span><span class="n">logvar</span><span class="p">)</span>
  <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">eps</span><span class="o">*</span><span class="n">std</span>
</code></pre></div></div>

<h2 id="experiment-results">Experiment results</h2>

<h3 id="data-generation">Data generation</h3>

<p>At various points during training, I sampled a grid of points from the latent space. The points are linearly spaced coordinates on the unit square, transformed through the inverse Gaussian CDF. This results in a grid of points with evenly spaced quantiles of the Gaussian. In plain English (sort of), this means slicing the Gaussian into equal sized chunks.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">20</span>
<span class="bp">self</span><span class="o">.</span><span class="n">grid_x</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
<span class="bp">self</span><span class="o">.</span><span class="n">grid_y</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.95</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
</code></pre></div></div>

<p>The following gifs show the maturation of the model’s latent space and data generating capabilities at various points throughout training. At the beginning of the animations, the generated data are mostly noise. But as training (and the animation) progresses, you begin to recognize shapes. Keep in mind that the images you’re seeing here are essentially “fake”, in that they are not images from any dataset.</p>

<p>Animation throughout the entire training process:</p>

<p><img src="http://localhost:4000/images/vae/datagen_tracking.gif" alt="" width="500" class="align-center" /></p>

<p>Animation for just the early stages of training:
<img src="http://localhost:4000/images/vae/datagen_tracking_early.gif" alt="" width="500" class="align-center" /></p>

<p>The final state of the learned manifold after training has completed:
<img src="http://localhost:4000/images/vae/datagen_final.png" width="500" class="align-center" /></p>

<p>As you can see, there are regions dedicated to individual digits with smooth transitions in between. I tried hand drawing the boundaries between digits to aid the visualization:
<img src="http://localhost:4000/images/vae/datagen_final_handdrawn_partitions.png" width="500" class="align-center" /></p>

<h3 id="data-reconstruction">Data reconstruction</h3>

<p>At various points throughout training I also tracked how well the model was reconstructing five hand-selected images:</p>

<p><img src="http://localhost:4000/images/vae/output_6_0.png" alt="png" class="align-center" /></p>

<p>The following animation shows how the model’s ability to reconstruct data improves over the training process:</p>

<p><img src="http://localhost:4000/images/vae/recon_tracking_early.gif" alt="" width="320" class="align-center" /></p>

<h3 id="anomaly-detection">Anomaly detection</h3>

<p>Anomalous data can be detected by leveraging the probabilistic nature of the VAE. One way to detect anomalies is to measure the KL divergence between the encoder distribution <script type="math/tex">q_{\phi}(z_i \lvert x_i)</script> and the prior <script type="math/tex">p_{\theta}(z)</script> and compare it to the average across the training (or test) set.</p>

<p>I computed this KL divergence for every point in the training set and plotted the resulting distribution:</p>

<p><img src="http://localhost:4000/images/vae/kl_dist.png" alt="" width="400" class="align-center" /></p>

<p>I then generated a noise sample:</p>

<p><img src="http://localhost:4000/images/vae/noise.png" alt="" class="align-center" /></p>

<p>And calculated its KL divergence: 51.763. As you can see from the distribution plot, this value is a significant outlier and would be easy to detect using automated anomaly detection systems.</p>

<h2 id="pytorch-code">PyTorch Code</h2>

<p>The data loading, data transformation, model architecture, loss function, and training loop are presented in this section. Detailed discussion on the key points of implementation are discussed above, but additional code annotation is provided for clarity. For the full code including visualization generation and experiment execution, please see <a href="https://github.com/acetherace/alcore/tree/master/notebooks/VAE.ipynb">this notebook</a> on Github.</p>

<h3 id="imports-and-helpers">Imports and Helpers</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.utils.data</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span><span class="p">,</span> <span class="n">optim</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torchvision.utils</span> <span class="kn">import</span> <span class="n">save_image</span>

<span class="kn">from</span> <span class="nn">fastprogress</span> <span class="kn">import</span> <span class="n">master_bar</span><span class="p">,</span> <span class="n">progress_bar</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>

<span class="kn">import</span> <span class="nn">imageio</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</code></pre></div></div>

<p>Set configuration parameters for model training:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">199</span>
<span class="n">log_interval</span><span class="o">=</span><span class="mi">10</span>
<span class="n">device</span><span class="o">=</span><span class="s">'cpu'</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="load-and-prep-data">Load and Prep Data</h3>

<p>I added the <code class="highlighter-rouge">lambda x: x.round()</code> transformation to convert the images into binary form. We’re assuming the data likelihood to follow a Bernoulli distribution and this connection is more clear when the data is binary.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="nb">round</span><span class="p">()</span>
<span class="p">])</span>
</code></pre></div></div>

<p>I hand picked five images to use for visualizing reconstruction performance throughout training.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ds</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s">'../data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">xforms</span><span class="p">)</span>
<span class="n">recon_base_imgs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">22</span><span class="p">]:</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">ds</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">recon_base_imgs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
<span class="n">recon_base_img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">recon_base_imgs</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">del</span> <span class="n">ds</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">recon_base_img</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s">'none'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p><img src="http://localhost:4000/images/vae/output_6_0.png" alt="png" /></p>

<p>Instantiate data loaders.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s">'../data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                   <span class="n">transform</span><span class="o">=</span><span class="n">xforms</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span>
    <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s">'../data'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">xforms</span><span class="p">),</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
<span class="c"># (60000, 10000)</span>
</code></pre></div></div>

<h3 id="define-model-and-training-functions">Define Model and Training Functions</h3>

<p>The encoder and decoder modules are defined separately as <code class="highlighter-rouge">VAEEncoder</code> and <code class="highlighter-rouge">BernoulliVAEDecoder</code>, respectively.  The <code class="highlighter-rouge">BernoulliVAE</code> class combines them to form the full model. It allows for a variable number of hidden layers and hidden layer sizes in both the encoder and decoder. It uses the ReLU activation function at each hidden layer.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">VAEEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    Standard encoder module for variational autoencoders with tabular input and
    factorized Gaussian posterior.
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">latent_size</span><span class="p">):</span>
        <span class="s">"""
        Args:
            data_size (int): Dimensionality of the input data.
            hidden_sizes (list[int]): Sizes of hidden layers (not including the
                input layer or the latent layer).
            latent_size (int): Size of the latent space.
        """</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">data_size</span><span class="o">=</span><span class="n">data_size</span>

        <span class="c"># construct the encoder</span>
        <span class="n">encoder_szs</span> <span class="o">=</span> <span class="p">[</span><span class="n">data_size</span><span class="p">]</span> <span class="o">+</span> <span class="n">hidden_sizes</span>
        <span class="n">encoder_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">in_sz</span><span class="p">,</span><span class="n">out_sz</span><span class="p">,</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">encoder_szs</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">encoder_szs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
            <span class="n">encoder_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_sz</span><span class="p">,</span> <span class="n">out_sz</span><span class="p">))</span>
            <span class="n">encoder_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">encoder_layers</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_mu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoder_szs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">latent_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_logvar</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">encoder_szs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">latent_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">gaussian_param_projection</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_mu</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder_logvar</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">reparameterize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">):</span>
        <span class="n">std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mf">0.5</span><span class="o">*</span><span class="n">logvar</span><span class="p">)</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">std</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mu</span> <span class="o">+</span> <span class="n">eps</span><span class="o">*</span><span class="n">std</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gaussian_param_projection</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reparameterize</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span>


<span class="k">class</span> <span class="nc">BernoulliVAEDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    VAE decoder module that models a factorized multivariate Bernoulli
    distribution with a feed-forward neural net.
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="p">,</span> <span class="n">latent_size</span><span class="p">):</span>
        <span class="s">"""
        Args:
            data_size (int): Dimensionality of the input data.
            hidden_sizes (list[int]): Sizes of hidden layers (not including the
                input layer or the latent layer).
            latent_size (int): Size of the latent space.
        """</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>

        <span class="c"># construct the decoder</span>
        <span class="n">hidden_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">latent_size</span><span class="p">]</span> <span class="o">+</span> <span class="n">hidden_sizes</span>
        <span class="n">decoder_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">in_sz</span><span class="p">,</span><span class="n">out_sz</span><span class="p">,</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">hidden_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">:]):</span>
            <span class="n">decoder_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_sz</span><span class="p">,</span> <span class="n">out_sz</span><span class="p">))</span>
            <span class="n">decoder_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="n">decoder_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">data_size</span><span class="p">))</span>
        <span class="n">decoder_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">decoder_layers</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">BernoulliVAE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""
    VAE module that combines a `VAEEncoder` and a `BernoulliVAEDecoder` resulting
    in full VAE.
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_size</span><span class="p">,</span> <span class="n">encoder_szs</span><span class="p">,</span> <span class="n">latent_size</span><span class="p">,</span> <span class="n">decoder_szs</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>

        <span class="c"># if decoder_szs not specified, assume symmetry</span>
        <span class="k">if</span> <span class="n">decoder_szs</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">decoder_szs</span> <span class="o">=</span> <span class="n">encoder_szs</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="c"># construct the encoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">VAEEncoder</span><span class="p">(</span><span class="n">data_size</span><span class="o">=</span><span class="n">data_size</span><span class="p">,</span> <span class="n">hidden_sizes</span><span class="o">=</span><span class="n">encoder_szs</span><span class="p">,</span>
                                  <span class="n">latent_size</span><span class="o">=</span><span class="n">latent_size</span><span class="p">)</span>

        <span class="c"># construct the decoder</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">BernoulliVAEDecoder</span><span class="p">(</span><span class="n">data_size</span><span class="o">=</span><span class="n">data_size</span><span class="p">,</span> <span class="n">latent_size</span><span class="o">=</span><span class="n">latent_size</span><span class="p">,</span>
                                           <span class="n">hidden_sizes</span><span class="o">=</span><span class="n">decoder_szs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">data_size</span> <span class="o">=</span> <span class="n">data_size</span>

    <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">z</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">p_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">p_x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span>
</code></pre></div></div>

<p>The loss function is discussed in detail above.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Reconstruction + KL divergence losses summed over all elements and batch</span>
<span class="k">def</span> <span class="nf">loss_function</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">):</span>
    <span class="n">BCE</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">binary_cross_entropy</span><span class="p">(</span><span class="n">recon_x</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">),</span> <span class="n">reduction</span><span class="o">=</span><span class="s">'sum'</span><span class="p">)</span>

    <span class="c"># see Appendix B from VAE paper:</span>
    <span class="c"># Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014</span>
    <span class="c"># https://arxiv.org/abs/1312.6114</span>
    <span class="c"># 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)</span>
    <span class="n">KLD</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">logvar</span> <span class="o">-</span> <span class="n">mu</span><span class="o">.</span><span class="nb">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">logvar</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span>

    <span class="k">return</span> <span class="n">BCE</span> <span class="o">+</span> <span class="n">KLD</span>
</code></pre></div></div>

<p>Function to execute one epoch of training. This function also generates visualizations every <code class="highlighter-rouge">figure_interval</code> batches.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">mb</span><span class="p">,</span> <span class="n">figure_interval</span><span class="p">,</span> <span class="n">viz_helper</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="n">train_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">pb</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">parent</span><span class="o">=</span><span class="n">mb</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">batch_idx</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">pb</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">recon_batch</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">recon_batch</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">train_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">batch_idx</span> <span class="o">%</span> <span class="n">figure_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">viz_helper</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">train_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
</code></pre></div></div>

<p>Function to perform evaluation on the test set.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">mb</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="nb">eval</span><span class="p">()</span>
    <span class="n">test_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">pb</span> <span class="o">=</span> <span class="n">progress_bar</span><span class="p">(</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">parent</span><span class="o">=</span><span class="n">mb</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">data</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">test_loader</span><span class="p">:</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span>
            <span class="n">recon_batch</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">loss_function</span><span class="p">(</span><span class="n">recon_batch</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">logvar</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">test_loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_loader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
</code></pre></div></div>

<p>Function to fit the model over a number of epochs and generate visualizations.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">figure_interval</span><span class="p">,</span> <span class="n">viz_helper</span><span class="p">):</span>
    <span class="n">mb</span> <span class="o">=</span> <span class="n">master_bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">viz_helper</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">mb</span><span class="p">:</span>
        <span class="n">trn_loss</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">mb</span><span class="p">,</span> <span class="n">figure_interval</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">viz_helper</span><span class="o">=</span><span class="n">viz_helper</span><span class="p">)</span>
        <span class="n">tst_loss</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">mb</span><span class="p">)</span>
        <span class="n">mb</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">f</span><span class="s">'epoch {epoch}, train loss: {round(trn_loss,6)}, test loss: {round(tst_loss, 6)}'</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="vae-with-20-d-latent-space">VAE with 20-d Latent Space</h3>

<p>Train a VAE with a 20 dimensional latent space. This VAE will be used to generate the data reconstruction visualizations.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">viz_helper_20d</span> <span class="o">=</span> <span class="n">VAEVizHelper</span><span class="p">(</span><span class="n">recon_base_imgs</span><span class="p">,</span> <span class="n">datagen_tracking</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">BernoulliVAE</span><span class="p">(</span><span class="n">data_size</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">encoder_szs</span><span class="o">=</span><span class="p">[</span><span class="mi">400</span><span class="p">],</span> <span class="n">latent_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                     <span class="n">decoder_szs</span><span class="o">=</span><span class="p">[</span><span class="mi">400</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span>

<span class="c"># BernoulliVAE(</span>
<span class="c">#   (encoder): VAEEncoder(</span>
<span class="c">#     (encoder): Sequential(</span>
<span class="c">#       (0): Linear(in_features=784, out_features=400, bias=True)</span>
<span class="c">#       (1): ReLU()</span>
<span class="c">#     )</span>
<span class="c">#     (encoder_mu): Linear(in_features=400, out_features=20, bias=True)</span>
<span class="c">#     (encoder_logvar): Linear(in_features=400, out_features=20, bias=True)</span>
<span class="c">#   )</span>
<span class="c">#   (decoder): BernoulliVAEDecoder(</span>
<span class="c">#     (decoder): Sequential(</span>
<span class="c">#       (0): Linear(in_features=20, out_features=400, bias=True)</span>
<span class="c">#       (1): ReLU()</span>
<span class="c">#       (2): Linear(in_features=400, out_features=784, bias=True)</span>
<span class="c">#       (3): Sigmoid()</span>
<span class="c">#     )</span>
<span class="c">#   )</span>
<span class="c"># )</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">viz_helper_20d</span><span class="p">)</span>
</code></pre></div></div>
<p>Total time: 02:10 &lt;p&gt;epoch 1, train loss: 157.707501, test loss: 116.365121&lt;p&gt;epoch 2, train loss: 108.549474, test loss: 102.344373&lt;p&gt;epoch 3, train loss: 99.825192, test loss: 96.556084&lt;p&gt;epoch 4, train loss: 95.784532, test loss: 94.104183&lt;p&gt;epoch 5, train loss: 93.294786, test loss: 91.994745&lt;p&gt;epoch 6, train loss: 91.638687, test loss: 90.58567&lt;p&gt;epoch 7, train loss: 90.407814, test loss: 89.906129&lt;p&gt;epoch 8, train loss: 89.389802, test loss: 88.779571&lt;p&gt;epoch 9, train loss: 88.574026, test loss: 88.075248&lt;p&gt;epoch 10, train loss: 87.911918, test loss: 87.646744</p>

<h2 id="vae-with-2-d-latent-space">VAE with 2-d Latent Space</h2>

<p>Train a VAE with 2 dimensional latent space. This model will be used to generate the visualizations of data generation across the latent manifold. It is much easier to visualize a 2-d manifold.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">BernoulliVAE</span><span class="p">(</span><span class="n">data_size</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">encoder_szs</span><span class="o">=</span><span class="p">[</span><span class="mi">400</span><span class="p">,</span><span class="mi">150</span><span class="p">],</span> <span class="n">latent_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                     <span class="n">decoder_szs</span><span class="o">=</span><span class="p">[</span><span class="mi">150</span><span class="p">,</span><span class="mi">400</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span>

<span class="c"># BernoulliVAE(</span>
<span class="c">#   (encoder): VAEEncoder(</span>
<span class="c">#     (encoder): Sequential(</span>
<span class="c">#       (0): Linear(in_features=784, out_features=400, bias=True)</span>
<span class="c">#       (1): ReLU()</span>
<span class="c">#       (2): Linear(in_features=400, out_features=150, bias=True)</span>
<span class="c">#       (3): ReLU()</span>
<span class="c">#     )</span>
<span class="c">#     (encoder_mu): Linear(in_features=150, out_features=2, bias=True)</span>
<span class="c">#     (encoder_logvar): Linear(in_features=150, out_features=2, bias=True)</span>
<span class="c">#   )</span>
<span class="c">#   (decoder): BernoulliVAEDecoder(</span>
<span class="c">#     (decoder): Sequential(</span>
<span class="c">#       (0): Linear(in_features=2, out_features=150, bias=True)</span>
<span class="c">#       (1): ReLU()</span>
<span class="c">#       (2): Linear(in_features=150, out_features=400, bias=True)</span>
<span class="c">#       (3): ReLU()</span>
<span class="c">#       (4): Linear(in_features=400, out_features=784, bias=True)</span>
<span class="c">#       (5): Sigmoid()</span>
<span class="c">#     )</span>
<span class="c">#   )</span>
<span class="c"># )</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fit</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">viz_helper_2d</span><span class="p">)</span>
</code></pre></div></div>
<p>Total time: 02:50 &lt;p&gt;epoch 1, train loss: 164.487584, test loss: 159.490324&lt;p&gt;epoch 2, train loss: 155.384058, test loss: 152.910404&lt;p&gt;epoch 3, train loss: 150.389809, test loss: 149.377793&lt;p&gt;epoch 4, train loss: 147.043944, test loss: 146.478713&lt;p&gt;epoch 5, train loss: 144.72857, test loss: 144.263316&lt;p&gt;epoch 6, train loss: 142.759334, test loss: 143.399154&lt;p&gt;epoch 7, train loss: 141.358421, test loss: 141.273972&lt;p&gt;epoch 8, train loss: 140.11891, test loss: 141.396691&lt;p&gt;epoch 9, train loss: 139.222043, test loss: 140.119026&lt;p&gt;epoch 10, train loss: 138.443796, test loss: 140.24413</p>

<h2 id="conclusion">Conclusion</h2>

<p>In this post we drew the final connections between the abstract theory of variational autoencoders and a concrete implementation in PyTorch. By sampling a grid from the latent space and using the probabilistic decoder to map these samples into synthetic digits, we saw how the model has learned a highly structured latent space with smooth transitions between digit classes. We also discussed a simple example demonstrating how the VAE can be used for anomaly detection.</p>

<h2 id="resources">Resources</h2>

<p>[1] PyTorch, <a href="https://github.com/pytorch/examples/tree/master/vae">Basic VAE Example</a></p>

        
      </section>

      <footer class="page__meta">
        
        
  


  
  
  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="/tags/#machine-learning" class="page__taxonomy-item" rel="tag">machine learning</a>
    
    </span>
  </p>




        
          <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2019-07-07T00:00:00-06:00">July 07, 2019</time></p>
        
      </footer>

      <section class="page__share">
  
    <h4 class="page__share-title">Share on</h4>
  

  <a href="https://twitter.com/intent/tweet?text=Variational+Autoencoder+Code+and+Experiments%20http%3A%2F%2Flocalhost%3A4000%2Fvae-series%2Fvae-code-experiments" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Flocalhost%3A4000%2Fvae-series%2Fvae-code-experiments" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http%3A%2F%2Flocalhost%3A4000%2Fvae-series%2Fvae-code-experiments" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>


      
  <nav class="pagination">
    
      <a href="/vae-series/variational-inference" class="pagination--pager" title="Latent Variable Models, Expectation Maximization, and Variational Inference
">Previous</a>
    
    
      <a href="/vae-series/vae-theory" class="pagination--pager" title="Variational Autoencoder Theory
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You may also enjoy</h4>
      <div class="grid__wrapper">
        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/vae-series" rel="permalink">Blog Post Series: From KL Divergence to Variational Autoencoder in PyTorch
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  1 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Landing page for the blog post series
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/vae-series/vae-theory" rel="permalink">Variational Autoencoder Theory
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  15 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Transforming general theory into VAE-specific theory
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/vae-series/variational-inference" rel="permalink">Latent Variable Models, Expectation Maximization, and Variational Inference
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  7 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Introduction to the general theory of variational inference
</p>
  </article>
</div>

        
          



<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="/vae-series/kl-divergence" rel="permalink">A Quick Primer on KL Divergence
</a>
      
    </h2>
    
      <p class="page__meta"><i class="far fa-clock" aria-hidden="true"></i> 




  4 minute read
</p>
    
    <p class="archive__item-excerpt" itemprop="description">Introductory discussion on KL divergence with an emphasis on building intuition from the mathematics
</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><input type="search" id="search" aria-placeholder="Enter your search term..." class="search-input" tabindex="-1" placeholder="Enter your search term..." />
    <div id="results" class="results"></div></div>

      </div>
    

    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2019 Adam Lineberry. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>
  <script defer src="https://use.fontawesome.com/releases/v5.8.1/js/all.js" integrity="sha384-g5uSoOSBd7KkhAMlnQILrecXvzst9TdC09/VM+pjDTCM+1il8RHz5fKANTFFb+gQ" crossorigin="anonymous"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>







<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



  </body>
</html>
